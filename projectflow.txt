-------------------------Setting up project structure and notebook analysis---------------------------

1.  Creating GitHub repo, cloning it locally  
2.  Creating virtual environment named 'calories-ml' conda create -n calories-ml python=3.10 -y
3.  Activating the virtual environment - conda activate calories-ml 
4.  Installing packages inside venv - pip install numpy pandas matplotlib seaborn ipykernel scikit-learn xgboost notebook
5.  Conecting new venv with Jupyter - python -m ipykernel install --user --name=calories-ml --display-name "Python (calories-ml)"
6.  Starting Jupyter notebook while inside venv - jupyter notebook
7.  Analysis in notebook inlcuding EDA, preprocessing, model training and evaluation
8.  First gid add . - commit - push 

-------------------------Setup MLFlow on Dagshub ( Experiments Part)---------------------------

9.  DAagshub link: https://dagshub.com/dashboard 
10. Create > New Repo > Connect a repo > (Github) Connect > Select your repo > Connect
11. pip install dagshub & mlflow in virtual environment
12. First experiment - file called experiment1, connecting base model (xgboost) and doing few runs with changing hyperparameters (example with n_estimators change)
13. Second experiment - connecting and comparing base model vs another models and comparing results in MLFlow (we get best results for xgboost algorithm)
14. Third experiment - xgboost hyperparameters tuning to get the best model for predictions
15. Finishing and collecting all info in our first notebook where whole EDA started 
16. on terminal - dvc init 
17. create a local folder as "local_s3" (temporary work) 
18. on terminal - "dvc remote add -d mylocal local_s3"

------------------------Building an aplication---------------------------------------------------

19. Creating src directory where I will store all components (data_ingestion file, data_preprocessing etc..)
20. Creating src/data/data_ingestion.py (testing by loading local files then loading from AWS s3 bucket). Then create IAM user and create access and secret keys. 
    Inside src/connections create config.json file and add your AWS credentials for IAM user. Add data to s3 bucket before testing.
21. Creating src/data/data_preprocessing.py 
22. Creating src/features/feature_engineering.py 
23. Creating src/model/model_building.py 
24. Creating src/model/model_evaluation.py (testing locally first ,production code commented out, and connecting to dagshub mlflow)
25. Creating src/model/model_register.py (also testing locally first, production code commented out, and connecting to dagshub mlflow )
26. Creating dvc.yaml file (all components combined in pipeline)
27. Run dvc.yaml file using command dvc repro
28. pip install - dvc[s3] & awscli 
29. Checking/deleting dvc remote - [dvc remote list & dvc remote remove mylocal] , because we are going to use aws s3 bucket
30. Set aws cred using command - aws configure (user your access key and secret key that you created for IAM user, also can be found in config.json file) 
31. Add s3 as dvc remote storage - dvc remote add -d myremote s3://<bucket-name>
32. Run dvc status and dvc commit commands (check dvc lock file if everything is tracked)
33. dvc push (tracking files pushed to s3 bucket) - image name ./3_dvc_push_to_s3_bucket
34. Create new directory flask_app and inside that all files related to application. Change in flask_app/app.py file line 45, stages = ["Staging"]. 
35. Inside flask_app folder create requirements.txt file that will be used by docker (separated from project root folder requirements.txt file to reduce the size of Docker image).
    Do commands pip install pipreqs and after that cd flask_app & do "pipreqs . --force", this will put only neccessery packages for the app into requirements.txt file
36. pip install -r flask_app/requirements.txt (so you can install packages needed for aplication local testing) 
37. run app from root folder with command python -m flask_app.app (local app testing) - image 1_app_local_testing 
38. pip freeze > requirements.txt (saved in root folder, requirements for the whole project, you can install at the beggining of the project) 
39. Create .github/workflows/ci.yaml file (till line 38, dvc repro part)
40. Create key token on Dagshub for auth: Go to dagshub repo > Your settings > Tokens > Generate new token (name Calories-Burnt-Pred)
    >> Make sure to save token 
    >> Add this auth token to github project repository, go to security/secret&var/Actions and finally update on ci file (name )
41. git add ./commit/push but before pushing code check for down bellow: - image 4_CICD_first_pipeline 
    1. gitignore must have /data/ to not truck files in that folder (this is root data folder not scr/data so do not write /data in gitignore write /data/)
    2. create dagshub token and add to github repository secrets 
    3. check your script and comment local code but uncomment production code that uses dugshub token (model_evaluation.py, model_register.py,app.py)
    4. add AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, S3_BUCKET_NAME and AWS_REGION from your config.json file into GitHub secrets
    5. After succesfull CICD pipeline you should get new model on MLFLOW in stageing phase

42. Add directories "tests"&"scripts" and files within them. This will contain our test related scripts for CI.yaml. Each time when we run ci.yaml we need to test model and promote best one from Staging to Production phase. We are also testing the aplication.
43. Add, commit and push your code so new CICD pipeline is triggered and ci.yaml fun run till line 57. Images 5_CICD_second_pipeline and 6_Model_pushed_to_production_stage 
44. Change in flask_app/app.py file line 45, stages = ["Production"] . Before this step it was  stages = ["Staging"]

--------------------------- Moving to Docker -----------------------------------------------
45. Create dockerfile and start docker-desktop in background (first we will test image locally to check for potential bugs). Production code in Dockerfile is commented out in this phase.
46. Go to root dir and: "docker build -t calories-burnt-pred-app:latest ."    
47. Run image and create container with command: "docker run -p 8888:5000 calories-burnt-pred-app:latest" and your app will run on link http://127.0.0.1:8888/ check images 8_Docker_Container_Built and 9_Aplication_run_inside_Docker
48. Create AWS ECR repository called calories-burnt-pred-proj and add into GitHub secrets new one under name ECR_REPOSITORY value is calories-burnt-pred-proj. Another secrets you need to add is your AWS_ACCOUNT_ID
    Also add this permission to the IAM user: AmazonEC2ContainerRegistryFullAccess
49. Execute CICD pipeline till the stage where we build and push image to ECR (ci.yaml created till line 85) - images 10_Aplication_dockerized_and_pushed_on_ECR and 11_Docker_image_appear_on_ECR 

--------------------------- Setup required before moving to EKS deployment-------------------

50. * Run the following in PowerShell to see the AWS CLI path being used: Get-Command aws
    If the path points to your Anaconda environment (e.g., C:\Users\Personal\anaconda3\...), itâ€™s a conflicting installation.
    * Uninstall Python-Based AWS CLI(Remove the conflicting AWS CLI from your Python environment): pip uninstall awscli
    * Verify it's uninstalled: aws --version
    * Update Environment Variables:
    > Make sure the .msi AWS CLI path is in your system PATH (usually installed at C:\Program Files\Amazon\AWSCLIV2\aws.exe).
    > Add it to your PATH if missing: Open Control Panel > System > Advanced System Settings > Environment Variables. Under "System Variables," find Path, and add the AWS CLI path: C:\Program Files\Amazon\AWSCLIV2\
    > Test AWS CLI Again: aws --version

51. Download kubectl: Invoke-WebRequest -Uri "https://dl.k8s.io/release/v1.28.2/bin/windows/amd64/kubectl.exe" -OutFile "kubectl.exe"
    * Locate the Download: Get-Location
    * Move kubectl.exe to a directory in your system PATH, such as C:\Windows\System32, so command is: Move-Item -Path .\kubectl.exe -Destination "C:\Windows\System32"
    * Test if kubectl is properly installed: kubectl version --client


52. Download eksctl: Invoke-WebRequest -Uri "https://github.com/weaveworks/eksctl/releases/download/v0.158.0/eksctl_Windows_amd64.zip" -OutFile "eksctl.zip"
    * Extract eksctl: Expand-Archive -Path .\eksctl.zip -DestinationPath .
    * Move the extracted eksctl.exe file to C:\Windows\System32 or any folder in your system PATH: Move-Item -Path .\eksctl.exe -Destination "C:\Windows\System32\eksctl.exe"

53. Verify installations
    * Verify AWS CLI: aws --version
    * Verify kubectl: kubectl version --client
    * Verify eksctl: eksctl version

------------------------------------Create an EKS cluster--------------------------

54. Use down bellow command for EKS cluster creation 
    * eksctl create cluster --name flask-app-cluster --region us-east-1 --nodegroup-name flask-app-nodes --node-type t3.small --nodes 1 --nodes-min 1 --nodes-max 1 --managed

55. Update kubectl Config(Once the cluster is created, eksctl will automatically update your kubectl config file. However, you can verify and set it manually using:)
aws eks --region us-east-1 update-kubeconfig --name flask-app-cluster (This ensures your kubectl is pointing to the correct cluster.)

56. Check EKS Cluster Configuration Ensure you can access your EKS cluster by running down bellow command
    aws eks list-clusters

57. Verify the cluster status (you can also check on AWS EKS UI but here is how to check in cmd):
    aws eks --region us-east-1 describe-cluster --name flask-app-cluster --query "cluster.status"

58. Check cluster connectivity (you will see only one node becuase we request one node in our eks cluster creation command):
    kubectl get nodes

59. Check the namespaces:
    kubectl get namespaces

60. Deploy the app on EKS via CICD pipeline 
  >> edit ci.yaml, full file creation, creation of deployment.yaml, edit dockerfile (comment out code for local use and uncomment for production use)
  >> Also edit the security group for nodes and edit inbound rule for 5000 port (go into EC2, find instance that was automatically created during EKS cluster creation, go inside instance and in Security tab enter security groups. Edit inbound rules) - image 13_Change_inbound_rules_on_EKS_cluster_EC2
  >> Now by doing gid . , commit and push you will deploy the app 

46. Verify the deployment:
    kubectl get pods
    kubectl get svc


48. Once the LoadBalancer service is up, get the external IP:
kubectl get svc flask-app-service

49. Try externa-ip:5000 directly on url or on terminal : curl http://external-ip:5000
curl http://a6bf6255d5f61470c9782b8955c98271-1409247973.us-east-1.elb.amazonaws.com:5000
